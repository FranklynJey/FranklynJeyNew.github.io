<!Doctype html>
<html lang="en">
    <head>
        <title>Neural Parts: Learning Expressive 3D Shape Abstractions with Invertible Neural Networks</title>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="author" content="Despoina Paschalidou">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="icon" type="image/png" href="data/bunny.png"/>

        <link rel="stylesheet" type="text/css" href="style_project_page.css?cache=7733391418498779679">
        <link href="https://fonts.googleapis.com/css?family=Arvo|Roboto&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <style type="text/css">
            .side-text {
                width:60%;
                display:inline-block;
                vertical-align:top;
            }
            .side-image {
                width: 38%;
                display: inline-block;
                vertical-align: top;
            }
            .controls {
                margin-bottom: 10px;
            }
            .left-controls {
                display: inline-block;
                vertical-align: top;
                width: 80%;
            }
            .right-controls {
                display: inline-block;
                vertical-align: top;
                width: 19%;
                text-align: right;
            }
            .render_window {
                display: inline-block;
                vertical-align: middle;
                box-shadow: 1px 0px 5px black;
                margin-right: 10px;
                margin-bottom: 10px;
                width: calc(33% - 10px);
            }
            .progress {
                background: #666;
                position: relative;
                height: 5px;
                margin-bottom: -5px;
                display: none;
            }

            @media (max-width: 400px) {
                .render_window {
                    display: block;
                    width: 90%;
                    margin: 10px auto;
                }
            }
            @media (max-width: 700px) {
                .side-image {
                    display: block;
                    width: 80%;
                    margin: 10px auto;
                }
                .side-text {
                    display: block;
                    width: 100%;
                }
            }
        </style>
    </head>
    <body>
        <div class="section">
            <h1 class="project-title">
                Neural Parts: Learning Expressive 3D Shape Abstractions<br />
                with Invertible Neural Networks
            </h1>
            <div class="authors">
                <a href=https://paschalidoud.github.io/>
                    Despoina Paschalidou <sup>1,5,6</sup>
                </a>
                <a href=https://angeloskath.github.io/>
                    Angelos Katharopoulos <sup>3,4</sup>
                </a>
                <a href=http://cvlibs.net/>
                    Andreas Geiger <sup>1,2,5</sup>
                </a>
                <a href=https://www.cs.utoronto.ca/~fidler/>
                    Sanja Fidler <sup>6,7,8</sup>
                </a>
            </div>

            <div class="affiliations">
                <span><sup>1</sup> Autonomous Vision Group, MPI for
                    Intelligent Systems Tübingen</span>
                <span><sup>2</sup> University of Tübingen</span> <br/>
                <span><sup>3</sup> Idiap Research Institute, Switzerland</span>
                <span><sup>4</sup> École Polytechique Fédérale de Lausanne (EPFL)</span> <br/>
                <span><sup>5</sup> Max Planck ETH Center for Learning Systems</span>
                <span><sup>6</sup> NVIDIA</span>
                <span><sup>7</sup> University of Toronto</span>
                <span><sup>8</sup> Vector Institute</span>
            </div>

            <div class="project-conference">
                CVPR 2021
            </div>

            <div class="project-icons">
                <a href="https://arxiv.org/pdf/2004.01176.pdf">
                    <i class="fa fa-file"></i> <br/>
                    Paper
                </a>
                <a href="https://paschalidoud.github.io/neural_parts">
                    <i class="fa fa-github"></i> <br/>
                    Code (TBD)
                </a>
                <!--<a href="https://www.youtube.com/watch?v=QgD0NHbWVlU&vq=hd1080&autoplay=1">
                    <i class="fa fa-youtube-play"></i> <br/>
                    Video
                </a>-->
                <!--<a href="https://paschalidoud.github.io/data/Paschalidou2020CVPR_poster.pdf">
                    <i class="fa fa-picture-o"></i> <br/>
                    Poster
                </a>
                <a href="http://www.cvlibs.net/publications/Paschalidou2020CVPR_slides.pdf">
                    <i class="fa fa-file-powerpoint-o"></i> <br/>
                    Slides
                </a>
                <a href="https://autonomousvision.github.io/hierarchical-primitives/">
                    <i class="fa fa-newspaper-o"></i> <br/>
                    Blog
                </a>-->
            </div>

            <div class="teaser-image">
                <img src="projects/neural_parts/teaser.png" style="width:100%;">
                <p class="caption">Our model learns to parse 3D objects into
                geometrically accurate and semantically consistent part arrangements <strong>
                without any part-level supervision</strong>. Our evaluations on ShapeNet objects,
                D-FAUST humans and FreiHAND hands demonstrate that our primitives can capture complex
                geometries and thus simultaneously achieve geometrically accurate as well as
                interpretable reconstructions using an order of magnitude fewer primitives than
                state-of-the-art shape abstraction methods.</p>
                <figure style="width: 49%;">
                    <video class="centered" width="100%" controls muted loop autoplay>
                        <source src="projects/neural_parts/motivation_cvxnet.mp4" type="video/mp4"/>
                    </video>
                    <p class="caption">Existing primitive-based methods rely on
                    simple shapes for decomposing complex 3D shapes into
                    parts. As a result, they <strong>require a large number of primitives</strong>
                    for extracting accurate reconstructions. However, this results in <strong>
                    less interpretable shape abstractions</strong>, namely
                    <strong>primitives are not semantically meaningful parts</strong>.</p>
                </figure>
                <figure style="width: 49%;">
                    <video class="centered" width="100%" controls muted loop autoplay>
                        <source src="projects/neural_parts/motivation_ours.mp4" type="video/mp4"/>
                    </video>
                    <p class="caption">Neural Parts is a novel 3D primitive representation that can 
                    <strong>represent arbitrarily complex genus-zero shapes
                    </strong> and thus yield more <strong>geometrically accurate</strong> and
                    <strong>semantically meaningful</strong> shape abstractions compared to simpler primitives.</p>
                </figure>
            </div>

            <div class="section-title">Approach Overview</div>
            <div class="content">
                <div class="side-text"><p>Primitive-based representations seek to infer
                <strong>semantically consistent part arrangements across
                different object instances</strong>. Existing primitive-based
                methods rely on simple shapes for decomposing complex objects
                into parts such as cuboids, superquadrics, spheres or
                convexes. <strong>Due to their simple parametrization, these primitives
                have limited expressivity and cannot capture arbitrarily
                complex geometries</strong>. Therefore, <strong>existing part-based methods
                require a large number of primitives for extracting
                geometrically accurate reconstructions</strong>. However, using <strong>more
                primitives comes at the expense of less interpretable
                reconstructions</strong>. Namely, a primitive is not an identifiable
                part anymore.</p></div>
                <div class="side-image"><img src="projects/neural_parts/convexes_vs_nps.png" style="width:100%;"></div>
                <p>We introduce a novel 3D primitive representation that is
                defined as <strong>a deformation betweek shapes</strong> and is
                <strong>parametrized as a learned homeomorphic mapping</strong>
                implemented with an <strong>Invertible Neural Network
                (INN)</strong>. We argue that a primitive should be a non
                trivial genus-zero shape with well defined implicit and explicit representations. Using an INN allows us to efficiently compute
                the implicit and explicit representation of the predicted shape
                and impose various constraints on the predicted parts. In contrast to prior work,
                that directly predict the primitive parameters (i.e. centroids and sizes for cuboids
                and superquadrics and hyperplanes for convexes), we employ the INN to fully define each primitive.
                This allows us to have primitives that capture arbitrarily
                complex geometries, hence the ability of our model to parse
                objects into expressive shape abstractions that are more
                geometrically accurate using an order of magnitude fewer
                primitives compared to approaches that rely on simple convex
                shape primitives.
                </p>
                <img src="projects/neural_parts/architecture.png" style="width:100%;">
                <p class="caption">Given an input image and a watertight mesh
                of the target object we seek to learn a representation with M
                primitives that best describes the target object. We define our
                primitives via a deformation between shapes that is
                parametrized as a learned homeomorphism implemented with an
                Invertible Neural Network (INN). For each primitive, we seek to
                learn a homeomorphism between the 3D space of a simple
                genus-zero shape and the 3D space of the target object, such
                that the deformed shape matches a part of the target object. Due
                to its simple implicit surface definition and tesselation, we
                employ a sphere as our genus-zero shape. Note that using an INN
                allows us to efficiently compute the implicit and explicit representation of
                the predicted shape and impose various constraints on the predicted parts.</p>
            </div>

            <div class="section-title">Results</div>
            <div class="content">
                In the following interactive visualization, the naming of the
                parts has been done manually. However, <strong>the model had no part
                supervision during training</strong>. The semantic parts have
                emerged naturally from reconstructing the geometry.
                <h3>Animals</h3>
                <div id="animals">
                    <div class="controls">
                        <div class="left-controls">
                            Show
                            <input type="checkbox" id="animals_all" checked><label for="animals_all">all parts</label>
                            <input type="checkbox" id="animals_head"><label for="animals_head">heads</label>
                            <input type="checkbox" id="animals_neck"><label for="animals_neck">necks</label>
                            <input type="checkbox" id="animals_legs"><label for="animals_legs">legs</label>
                        </div>
                        <div class="right-controls">
                            <button>Randomize</button>
                        </div>
                    </div>
                    <div class="render_container">
                        <div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div>
                    </div>
                </div>

                <h3>Humans</h3>
                <div id="humans">
                    <div class="controls">
                        <div class="left-controls">
                            Show
                            <input type="checkbox" id="humans_all" checked><label for="humans_all">all parts</label>
                            <input type="checkbox" id="humans_head"><label for="humans_head">heads</label>
                            <input type="checkbox" id="humans_body"><label for="humans_body">bodies</label>
                            <input type="checkbox" id="humans_left_hand"><label for="humans_left_hand">left-arms</label>
                            <input type="checkbox" id="humans_right_hand"><label for="humans_right_hand">right-arms</label>
                            <input type="checkbox" id="humans_left_leg"><label for="humans_left_leg">left-legs</label>
                            <input type="checkbox" id="humans_right_leg"><label for="humans_right_leg">right-legs</label>
                        </div>
                        <div class="right-controls">
                            <button>Randomize</button>
                        </div>
                    </div>
                    <div class="render_container">
                        <div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div><div data-size="400" class="render_window"></div>
                    </div>
                </div>

                <!--
                <h3>Planes</h3>
                <div id="animals">
                    <div class="controls">
                        Show
                        <input type="checkbox" id="animals_all" checked><label for="animals_all">all parts</label>
                        <input type="checkbox" id="animals_head" checked><label for="animals_head">heads</label>
                        <input type="checkbox" id="animals_neck" checked><label for="animals_neck">necks</label>
                        <input type="checkbox" id="animals_legs" checked><label for="animals_legs">legs</label>
                    </div>
                    <div class="render_large">
                        <div data-size="400" class="render_window"></div>
                    </div>
                    <div class="render_small">
                        <div data-size="200" class="render_window"></div><div data-size="200" class="render_window"></div><div data-size="200" class="render_window"></div><div data-size="200" class="render_window"></div>
                    </div>
                </div>-->
            </div>

            <div class="section-title">Acknowledgements</div>
            <div class="content">
                This research was supported by the Max Planck ETH Center for
                Learning Systems. We would like to thank <a href=https://kangxue.org/>Kangxue Yin </a>for
                providing the 3D models for the animal dataset.
            </div>
        </div>

        <script type="module">

            import * as THREE from "https://unpkg.com/three/build/three.module.js";
            import { OrbitControls } from "https://unpkg.com/three/examples/jsm/controls/OrbitControls.js";
            import {OBJLoader} from "https://unpkg.com/three/examples/jsm/loaders/OBJLoader.js";

            function random_choice(arr, n) {
                var index_set = {};
                var choice = [];
                while (choice.length < n) {
                    var idx = Math.floor(Math.random() * arr.length);
                    if (index_set[idx] !== undefined) {
                        continue;
                    }
                    index_set[idx] = 0;
                    choice.push(idx);
                }

                return choice.map(x => arr[x]);
            }

            function progress_bar() {
                var el = document.createElement("div");
                el.classList.add("progress");

                return {
                    domElement: el,
                    update: function (percent) {
                        percent = Math.min(1, Math.max(0, percent));
                        el.style.display = "block";
                        el.style.width = Math.round(percent * 100) + "%";
                    },
                    hide: function () {
                        el.style.display = "none";
                    }
                };
            }

            function show_object(el, prefix, N) {
                const scene = new THREE.Scene();
                const renderer = new THREE.WebGLRenderer();
                const camera = new THREE.PerspectiveCamera(75, 1, 0.1, 1000);
                const controls = new OrbitControls(camera, renderer.domElement);

                camera.position.set(0.5, 0.5, 0.5);
                controls.target.set(0, 0, 0);
                controls.autoRotate = true;
                controls.autoRotateSpeed = 4;
                scene.background = new THREE.Color("white");
                var size = el.dataset.size;
                renderer.setSize(size, size);
                var progress = progress_bar();
                el.appendChild(progress.domElement);
                el.appendChild(renderer.domElement);

                const amb_light = new THREE.AmbientLight(0x606060); // soft white light
                scene.add(amb_light);
                const hem_light = new THREE.HemisphereLight(0xffffbb, 0x080820, 0.5);
                scene.add(hem_light);

                const colors = [
                    0x1f77b4,
                    0xaec7e8,
                    0xff7f0e,
                    0xffbb78,
                    0x2ca02c,
                    0x98df8a,
                    0xd62728,
                    0xff9896,
                    0x9467bd,
                    0xc5b0d5,
                    0x8c564b,
                    0xc49c94,
                    0xe377c2,
                    0xf7b6d2,
                    0x7f7f7f,
                    0xc7c7c7,
                    0xbcbd22,
                    0xdbdb8d,
                    0x17becf,
                    0x9edae5
                ];
                var previous_canvas_size = size;
                function animate() {
                    requestAnimationFrame(animate);
                    if (el.offsetWidth != previous_canvas_size) {
                        previous_canvas_size = el.offsetWidth;
                        renderer.domElement.style.width = previous_canvas_size + "px";
                        renderer.domElement.style.height = previous_canvas_size + "px";
                    }

                    controls.update();
                    renderer.render(scene, camera);
                }

                const loader = new OBJLoader();
                var meshes = [];
                var progresses = [];
                var loaded = 0;
                function load_part(part_idx) {
                    progresses[part_idx] = 0;
                    loader.load(
                        prefix + "/part_00" + i + ".obj",
                        function (object) {
                            var g = object.children[0].geometry;
                            var m = new THREE.MeshLambertMaterial({color: colors[part_idx]});
                            m.transparent = true;
                            var mesh = new THREE.Mesh(g, m);
                            meshes[part_idx] = mesh;
                            scene.add(mesh);

                            loaded++;
                            if (loaded == N) {
                                progress.hide();
                            }
                        },
                        function (event) {
                            progresses[part_idx] = event.loaded / event.total;
                            var total_progress = 0;
                            for (var i=0; i<progresses.length; i++) {
                                total_progress += progresses[i] / progresses.length;
                            }
                            progress.update(total_progress);
                        }
                    )
                }
                for (var i=0; i<N; i++) {
                    load_part(i);
                }
                animate();

                return {
                    meshes: meshes,
                    show: function (indices) {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 0.5;
                            //meshes[i].visible = false;
                        }
                        for (var i=0; i<indices.length; i++) {
                            meshes[indices[i]].material.opacity = 1;
                            //meshes[indices[i]].visible = true;
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<N; i++) {
                            meshes[i].material.opacity = 1;
                            //meshes[i].visible = true;
                        }
                    },
                    set_size: function(width, height) {
                        renderer.setSize(width, height);
                    }
                };
            }

            function show_group(elements, objects, N) {
                var controls = [];
                for (var i=0; i<objects.length; i++) {
                    controls.push(show_object(elements[i], objects[i], N));
                }

                return {
                    controls: controls,
                    show: function (indices) {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show(indices);
                        }
                    },
                    show_all: function () {
                        for (var i=0; i<controls.length; i++) {
                            controls[i].show_all();
                        }
                    }
                };
            }

            // Animals
            var animals = [
                "projects/neural_parts/objects/animals/1422165",
                "projects/neural_parts/objects/animals/692032",
                "projects/neural_parts/objects/animals/626525",
                "projects/neural_parts/objects/animals/745737",
                "projects/neural_parts/objects/animals/721005"
            ];
            var animal_control = show_group(
                document.getElementById("animals").getElementsByClassName("render_window"),
                [animals[0], animals[1], animals[2]],
                8
            );
            var animal_checkboxes = document.querySelectorAll("#animals .controls input");
            document.querySelector("#animals .controls").addEventListener(
                "change",
                function (ev) {
                    if (ev.target.id == "animals_all") {
                        Array.prototype.filter.call(
                            animal_checkboxes,
                            (el) => el.id != "animals_all"
                        ).forEach(function (el) {el.checked = false;});
                    } else if (ev.target.checked) {
                        animal_checkboxes[0].checked = false;
                    }

                    var ids = new Set();
                    if (animal_checkboxes[0].checked) {
                        ids = new Set([0, 1, 2, 3, 4, 5, 6, 7]);
                    }
                    if (animal_checkboxes[1].checked) {
                        ids.add(3);
                    }
                    if (animal_checkboxes[2].checked) {
                        ids.add(4);
                    }
                    if (animal_checkboxes[3].checked) {
                        ids.add(2);
                        ids.add(6);
                        ids.add(7);
                    }

                    animal_control.show(Array.from(ids));
                }
            );
            document.querySelector("#animals .controls button").addEventListener(
                "click",
                function (ev) {
                    var new_animals = random_choice(animals, 3);
                    var render_windows = document.getElementById("animals").getElementsByClassName("render_window");
                    Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
                    animal_control = show_group(
                        render_windows,
                        new_animals,
                        8
                    );
                }
            );

            // Humans
            var humans = [
                "projects/neural_parts/objects/humans/50020_knees_00136",
                "projects/neural_parts/objects/humans/50009_jumping_jacks_00140",
                "projects/neural_parts/objects/humans/50002_jumping_jacks_00038",
                "projects/neural_parts/objects/humans/50009_one_leg_jump_00075",
                "projects/neural_parts/objects/humans/50004_running_on_spot_00220",
                "projects/neural_parts/objects/humans/50022_punching_00069"
            ];
            var human_control = show_group(
                document.getElementById("humans").getElementsByClassName("render_window"),
                [humans[0], humans[1], humans[2]],
                6
            );
            var human_checkboxes = document.querySelectorAll("#humans .controls input");
            document.querySelector("#humans .controls").addEventListener(
                "change",
                function (ev) {
                    if (ev.target.id == "humans_all") {
                        Array.prototype.filter.call(
                            human_checkboxes,
                            (el) => el.id != "humans_all"
                        ).forEach(function (el) {el.checked = false;});
                    } else if (ev.target.checked) {
                        human_checkboxes[0].checked = false;
                    }

                    var ids = new Set();
                    if (human_checkboxes[0].checked) {
                        ids = new Set([0, 1, 2, 3, 4, 5]);
                    }
                    var part_ids = [1, 2, 0, 4, 3, 5];
                    for (var i=1; i<human_checkboxes.length; i++) {
                        if (human_checkboxes[i].checked) {
                            ids.add(part_ids[i-1]);
                        }
                    }

                    human_control.show(Array.from(ids));
                }
            );
            document.querySelector("#humans .controls button").addEventListener(
                "click",
                function (ev) {
                    var new_humans = random_choice(humans, 3);
                    var render_windows = document.getElementById("humans").getElementsByClassName("render_window");
                    Array.prototype.forEach.call(render_windows, function (r) {r.innerHTML = "";});
                    animal_control = show_group(
                        render_windows,
                        new_humans,
                        6
                    );
                }
            );
        </script>
    </body>
</html>
